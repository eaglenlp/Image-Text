# Image-Text Papers

## Introduction

## Papers

# Image Captioning
1. Unified Vision-Language Pre-Training for Image Captioning and VQA. *AAAI 2020*. [[PDF](https://arxiv.org/abs/1909.11059)] [[github repo](https://github.com/LuoweiZhou/VLP)]
2. 

# Image-Text Matching
1. Few-Shot Image and Sentence Matching via Gated Visual-Semantic Embedding. *AAAI 2019*. [[PDF](https://www.aaai.org/ojs/index.php/AAAI/article/download/4866/4739)]
2. Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching. *IJCAI 2019*. [[PDF](https://www.ijcai.org/proceedings/2019/0111.pdf)]
3. Knowledge Aware Semantic Concept Expansion for Image-Text Matching. *IJCAI 2019*. [[PDF](https://www.ijcai.org/proceedings/2019/0720.pdf)]
4. Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching. *IJCAI 2019*. [[PDF](https://www.ijcai.org/proceedings/2019/0111.pdf)]
5. Position Focused Attention Network for Image-Text Matching. *IJCAI 2019*. [[PDF](https://arxiv.org/pdf/1907.09748)]
6. Neural Compatibility Ranking for Text-based Fashion Matching. *SIGIR 2019*. [[PDF](https://unsuthee.github.io/about/SIGIR2019_Compatible_Matching.pdf)]
7. Prototype-guided Attribute-wise Interpretable Scheme for Clothing Matching. *SIGIR 2019*. [[PDF](https://xuemengsong.github.io/SIGIR2019_PAICM.pdf)]
8. HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs [[PDF](https://arxiv.org/abs/1911.10097)]

# Multimodal Retrieval
1. **Composing Text and Image for Image Retrieval - An Empirical Odyssey**. *CVPR 2019*. [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Vo_Composing_Text_and_Image_for_Image_Retrieval_-_an_Empirical_CVPR_2019_paper.pdf)]
2. **Integrating Text and Image Determining Multimodal Document Intent in Instagram Posts**. *EMNLP 2019*. [[PDF](https://arxiv.org/pdf/1904.09073)]
3. **VrR-VG Refocusing Visually-Relevant Relationships**. *ICCV 2019*. [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Liang_VrR-VG_Refocusing_Visually-Relevant_Relationships_ICCV_2019_paper.pdf)]
4. **Grounded compositional semantics for finding and describing images with sentences**. *ACL 2014*. [[PDF](https://nlp.stanford.edu/~socherr/SocherKarpathyLeManningNg_TACL2013.pdf)]
5. **Learning Disentangled Representation for Cross-Modal Retrieval with Deep Mutual Information Estimation**. *MM 2019*. [[PDF(https://dl.acm.org/citation.cfm?id=3351053)]]
